# Тестовое задание Xindata

## Описание задачи

Реализован прототип системы, анализирующей статистические данные о доходах фрилансеров и отвечающей на вопросы на естественном языке. Использован датасет [Freelancer Earnings and Job Trends](https://www.kaggle.com/datasets/andrewmvd/freelancer-earnings-and-job-trends).

### Рассуждения по выбору подхода

Были рассмотрены следующие основные подходы:

1.  **Использование LLM для генерации исполняемого кода (например, Python/Pandas):**
    *   LLM получает описание DataFrame и генерирует код для анализа.
    *   *Недостатки:* Основной риск — безопасность. Требует сложной "песочницы" и тщательной валидации. 
    
2.  **Использование LLM с механизмом Function Calling / Tools:**
    *   Определяется набор Python-функций, которые LLM может "вызывать" для получения данных. LLM решает, какую функцию и с какими параметрами вызвать.
    *   *Преимущества:* Относительно безопасно, хорошо контролируется. LLM использует функции из предопределенного пула.
    *   *Комментарий:* Для данной задачи, где конечной целью является запрос к реляционной базе данных, генерация SQL показалась более прямым путем. Однако, для более сложных сценариев или интеграций с другими системами, Function Calling возможно, был бы предпочтительнее.

3.  **Использование LLM для генерации SQL-запросов (Выбранный подход):**
    *   **Описание:**
        1.  LLM получает схему таблицы.
        2.  На основе вопроса пользователя LLM генерирует SQL-запрос (только SELECT).
        3.  Этот SQL-запрос валидируется (на предмет отсутствия DML/DDL, потенциально опасных конструкций, через `EXPLAIN`) и затем выполняется над базой данных.
        4.  Результат запроса передается обратно LLM для формирования ответа на естественном языке или форматируется напрямую.
    *   **Преимущества для данного проекта:**
        *   **Соответствие ограничениям:** LLM работает только со схемой, не видя сами данные.
        *   **Использование сильных сторон LLM:** Эффективное преобразование естественного языка в структурированный запрос.
        *   **Стандартный интерфейс к данным:** SQL — мощный и универсальный язык для запросов к структурированным данным. SQLite легковесна и не требует отдельного сервера, что удобно для прототипа.
        *   **Контроль и безопасность:** Возможность строгой валидации генерируемых SQL-запросов. В текущей реализации разрешены только `SELECT`, что минимизирует риски. Использование `EXPLAIN` помогает в предварительной оценке запроса.

4.  **Retrieval Augmented Generation (RAG):**
    *   Индексация предварительно агрегированных данных или текстовых описаний и их использование в качестве контекста для LLM.
    *   *Недостатки для основного решения:* Менее гибок для произвольных аналитических запросов к сырым (или почти сырым) данным. Больше подходит для ответов на основе существующей базы знаний, а не для динамического анализа. Больше подходит к тексту, нежели к цифрам. Непонятно как чанковать данные.

**Итоговый выбор:** Подход с генерацией SQL-запросов языковой моделью (Gemini) был выбран как оптимальный баланс между гибкостью обработки запросов на естественном языке, безопасностью, возможностью контроля и эффективностью работы со структурированными данными в SQLite. Он позволяет LLM выступать в роли "переводчика" с естественного языка на язык SQL, при этом сама логика извлечения и обработки данных остается на стороне надежной и проверенной СУБД.



## Архитектура и стек

- **Языковая модель (LLM):** Google Gemini, личное предпочтение, ничем не обсуловленное.
- **CLI:** asyncclick — асинхронный интерфейс командной строки.
- **БД:** SQLite (через aiosqlite) — простая интеграция, не требует отдельного сервера.
- **Обработка данных:** pandas — для чтения и импорта CSV.
- **Конфигурация:** python-dotenv, pydantic.
- **Тесты:** pytest, pytest-asyncio.


## Структура проекта

- `src/cli.py` — основной CLI-интерфейс.
- `src/db.py` — работа с БД и валидация SQL.
- `src/llm.py` — интеграция с LLM.
- `src/config.py` — конфигурация.
- `data/` — CSV и БД.
- `tests/` — тесты.

## Как запустить

1. Клонируйте репозиторий и перейдите в папку проекта.
2. Создайте и активируйте виртуальное окружение:
   ```bash
   python3 -m venv venv && source venv/bin/activate
   ```
3. Установите зависимости:
   ```bash
   pip install -r requirements.txt
   ```
4. Создайте файл `.env` (см. пример в `.env.example`):
   ```env
   GEMINI_API_KEY=ваш_ключ
   GEMINI_MODEL=gemini-2.0-flash
   ```
5. Инициализируйте БД:
   ```bash
   python3 -m src.cli init
   ```
6. Задайте вопрос:
   ```bash
   python3 -m src.cli ask "Какой средний доход у экспертов?"
   ```
7. Демонстрация(много вопросов сразу):
   ```bash
   python3 -m src.cli demo
   ```

## Примеры вопросов

- Насколько выше доход у фрилансеров, принимающих оплату в криптовалюте, по сравнению с другими способами оплаты?
- Как распределяется доход фрилансеров в зависимости от региона проживания?
- Какой процент фрилансеров, считающих себя экспертами, выполнил менее 100 проектов?
- Средний рейтинг клиентов для проектов длительностью более 30 дней?
- Сколько фрилансеров были повторно наняты?
- Сколько фрилансеров имеют доход выше 1000?
- Сколько проектов выполнено в 2023 году?
- Какой средний доход у фрилансеров с рейтингом выше 4.5?
- Сколько фрилансеров работают из Европы?
- Какой максимальный доход среди всех?

## Ограничения
- LLM не видит данные напрямую, только схему таблицы (описание полей).
- Разрешены только SELECT-запросы, любые DML/DDL блокируются.
- Ответы на неаналитические вопросы (smalltalk/help) определяются автоматически.

## Тестирование

- Запуск тестов:
  ```bash
  PYTHONPATH=$(pwd) pytest
  ```
- Покрытие: тестируются сценарии CLI, валидация SQL, обработка ошибок, интеграция с LLM (заглушка).

## Оценка эффективности и критерии качества

- **Критерии:**
  - Корректность SQL, генерируемого LLM (валидируется через EXPLAIN).
  - Корректность ответов на тестовые вопросы (сравнение с ожидаемым результатом).
  - CLI не падает на невалидных/опасных запросах.
  - Корректная обработка smalltalk/help/unknown.
- **Что работает:**
  - SQL корректно валидируется и выполняется.
  - LLM не может выполнить опасные запросы.
  - CLI устойчив к ошибкам.


    
## Самооценка

- Код покрыт тестами, структура модульная.
- CLI удобен, ошибки обрабатываются.
- LLM не видит данные напрямую, только схему.
- Критерии качества соблюдены: корректность SQL, устойчивость к ошибкам, безопасность.
